{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Deep Research AI Agent\n",
        "!pip install langchain-openai\n",
        "!pip install langgraph\n",
        "!pip install tavily-python\n",
        "!pip install langchain-openai langchain-core langgraph tavily-python --quiet\n",
        "import os\n",
        "from getpass import getpass\n",
        "from typing import TypedDict, List, Dict, Any\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langgraph.graph import StateGraph, END\n",
        "from tavily import TavilyClient\n",
        "\n"
      ],
      "metadata": {
        "id": "60bFyei-peEX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9ae1f19-8c70-400c-c8e5-7d8c7206a37c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.11/dist-packages (0.3.14)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.53 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.3.55)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.68.2 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (1.75.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.9.0)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.53->langchain-openai) (0.3.31)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.53->langchain-openai) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.53->langchain-openai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.53->langchain-openai) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.53->langchain-openai) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.53->langchain-openai) (4.13.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.53->langchain-openai) (2.11.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.68.2->langchain-openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain-openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain-openai) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain-openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.53->langchain-openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.53->langchain-openai) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.53->langchain-openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.53->langchain-openai) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.53->langchain-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.53->langchain-openai) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.53->langchain-openai) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.3.0)\n",
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.11/dist-packages (0.3.33)\n",
            "Requirement already satisfied: langchain-core<0.4,>=0.1 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.3.55)\n",
            "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.10 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.0.24)\n",
            "Requirement already satisfied: langgraph-prebuilt<0.2,>=0.1.8 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.1.8)\n",
            "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.1.63)\n",
            "Requirement already satisfied: xxhash<4.0.0,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (0.3.31)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (4.13.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (2.11.3)\n",
            "Requirement already satisfied: ormsgpack<2.0.0,>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph) (1.9.1)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.16)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.8)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.1->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.1->langgraph) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.1->langgraph) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (2.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.3.1)\n",
            "Requirement already satisfied: tavily-python in /usr/local/lib/python3.11/dist-packages (0.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from tavily-python) (2.32.3)\n",
            "Requirement already satisfied: tiktoken>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from tavily-python) (0.9.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from tavily-python) (0.28.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.5.1->tavily-python) (2024.11.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->tavily-python) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->tavily-python) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->tavily-python) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->tavily-python) (2025.1.31)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->tavily-python) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->tavily-python) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->tavily-python) (0.14.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx->tavily-python) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx->tavily-python) (4.13.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set API keys securely using getpass\n",
        "print(\"Enter your API keys\")\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass(\"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\")\n",
        "os.environ[\"TAVILY_API_KEY\"] = getpass(\"sk-proj-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\")\n",
        "print(\"API keys set.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2G2dYSLzYFMU",
        "outputId": "b9df6315-9b30-4d24-8e2a-1934c5c5f9fc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your API keys\n",
            "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··········\n",
            "sk-proj-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··········\n",
            "API keys set.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Initialize LLM and Tavily client\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "tavily_client = TavilyClient(api_key=os.environ[\"TAVILY_API_KEY\"])\n",
        "print(\"LLM and Tavily client initialized.\")\n",
        "\n",
        "# Define shared state\n",
        "class ResearchState(TypedDict):\n",
        "    query: str\n",
        "    research_data: List[Dict[str, Any]]\n",
        "    draft_answer: str\n",
        "    final_answer: str\n",
        "\n",
        "# Research Agent: Collects data using Tavily\n",
        "def research_agent(state: ResearchState) -> ResearchState:\n",
        "    query = state[\"query\"]\n",
        "    try:\n",
        "        search_results = tavily_client.search(query=query, search_depth=\"advanced\", max_results=5)\n",
        "        research_data = [\n",
        "            {\n",
        "                \"title\": result[\"title\"],\n",
        "                \"url\": result[\"url\"],\n",
        "                \"content\": result[\"content\"],\n",
        "                \"source\": result.get(\"source\", \"web\")\n",
        "            }\n",
        "            for result in search_results[\"results\"]\n",
        "        ]\n",
        "        state[\"research_data\"] = research_data\n",
        "    except Exception as e:\n",
        "        print(f\"Error in research_agent: {e}\")\n",
        "        state[\"research_data\"] = []\n",
        "    return state"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvjAb9SuYGpi",
        "outputId": "40e4c828-0a2f-4ac1-f08b-235e38fd374f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM and Tavily client initialized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Answer Drafter Agent: Synthesizes research into a response\n",
        "def answer_drafter_agent(state: ResearchState) -> ResearchState:\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        SystemMessage(content=\"You are an expert answer drafter. Synthesize the provided research data into a concise, accurate, and well-structured response to the user's query. Cite sources where appropriate.\"),\n",
        "        HumanMessage(content=f\"\"\"Query: {state['query']}\\n\\nResearch Data:\\n{state['research_data']}\\n\\nProvide a clear and concise answer.\"\"\")\n",
        "    ])\n",
        "    try:\n",
        "\n",
        "        formatted_prompt = prompt.format_prompt(query=state['query'], research_data=state['research_data'])\n",
        "        response = llm.invoke(formatted_prompt.to_messages())\n",
        "        state[\"draft_answer\"] = response.content\n",
        "    except Exception as e:\n",
        "        print(f\"Error in answer_drafter_agent: {e}\")\n",
        "        state[\"draft_answer\"] = \"Failed to draft answer.\"\n",
        "    return state\n",
        "\n",
        "# Final Answer Refiner: Polishes the draft answer\n",
        "def final_answer_refiner(state: ResearchState) -> ResearchState:\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        SystemMessage(content=\"You are a final answer refiner. Improve the draft answer for clarity, coherence, and professionalism. Ensure it directly addresses the query.\"),\n",
        "        HumanMessage(content=f\"\"\"Draft Answer: {state['draft_answer']}\\n\\nQuery: {state['query']}\\n\\nRefine the draft into a polished response.\"\"\")\n",
        "    ])\n",
        "    try:\n",
        "\n",
        "        formatted_prompt = prompt.format_prompt(draft_answer=state['draft_answer'], query=state['query'])\n",
        "        response = llm.invoke(formatted_prompt.to_messages())\n",
        "        state[\"final_answer\"] = response.content\n",
        "    except Exception as e:\n",
        "        print(f\"Error in final_answer_refiner: {e}\")\n",
        "        state[\"final_answer\"] = state[\"draft_answer\"]\n",
        "    return state\n",
        "\n",
        "\n",
        "# Define the LangGraph workflow\n",
        "def create_research_workflow():\n",
        "    workflow = StateGraph(ResearchState)\n",
        "    workflow.add_node(\"research\", research_agent)\n",
        "    workflow.add_node(\"drafter\", answer_drafter_agent)\n",
        "    workflow.add_node(\"refiner\", final_answer_refiner)\n",
        "    workflow.set_entry_point(\"research\")\n",
        "    workflow.add_edge(\"research\", \"drafter\")\n",
        "    workflow.add_edge(\"drafter\", \"refiner\")\n",
        "    workflow.add_edge(\"refiner\", END)\n",
        "    workflow.add_edge(\"drafter\", END)\n",
        "    return workflow.compile()"
      ],
      "metadata": {
        "id": "c2CCkfogYfCV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Main function to run the system\n",
        "def run_deep_research(query: str) -> str:\n",
        "    workflow = create_research_workflow()\n",
        "    initial_state = ResearchState(\n",
        "        query=query,\n",
        "        research_data=[],\n",
        "        draft_answer=\"\",\n",
        "        final_answer=\"\"\n",
        "    )\n",
        "    try:\n",
        "        result = workflow.invoke(initial_state)\n",
        "        return result[\"final_answer\"] if \"final_answer\" in result else result[\"draft_answer\"]\n",
        "    except Exception as e:\n",
        "        print(f\"Error in workflow: {e}\")\n",
        "        return \"Failed to generate final answer.\"\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    query = input(\"Enter your query: \")\n",
        "   #print(f\"\\nRunning query: {query}\")\n",
        "    final_answer = run_deep_research(query)\n",
        "   #print(f\"\\nQuery: {query}\\n\")\n",
        "    print(f\"Final Answer:\\n{final_answer}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__u4QLRUYiXt",
        "outputId": "7e664911-0105-4e84-ae74-1e372382e87a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your query: aplications of quantum dots\n",
            "Final Answer:\n",
            "Quantum dots (QDs) are semiconductor nanomaterials renowned for their unique optical and electronic properties, which enable a diverse array of applications across multiple fields. Below are some of the key applications of quantum dots:\n",
            "\n",
            "1. **Biomedical Applications**: Quantum dots are widely utilized in bioimaging, drug delivery, and medical diagnostics. They function as fluorescent labels for intracellular imaging and can be engineered for specific targeting in in vivo imaging systems. Additionally, QDs are being investigated for cancer photodynamic therapy, where they can selectively accumulate in tumor tissues and generate reactive oxygen species (ROS) upon irradiation, effectively targeting and destroying cancer cells.\n",
            "\n",
            "2. **Optoelectronics**: Quantum dots play a crucial role in the development of light-emitting diodes (LEDs), lasers, and solar cells. Their emission wavelengths can be precisely tuned by altering their size, making them ideal for applications in color conversion and advanced display technologies.\n",
            "\n",
            "3. **Quantum Computing and Cryptography**: Researchers are exploring the potential of quantum dots in quantum computing and cryptography, as they can serve as qubits, the fundamental units of quantum information.\n",
            "\n",
            "4. **Sensors and Diagnostics**: Due to their high sensitivity and specificity, quantum dots are employed in various sensor applications, including environmental monitoring and medical diagnostics.\n",
            "\n",
            "5. **Microscopy and Imaging Techniques**: Quantum dots enhance imaging techniques such as fluorescence microscopy and confocal laser scanning microscopy, providing high-resolution images that are invaluable for cellular and molecular studies.\n",
            "\n",
            "In summary, the versatility of quantum dots positions them as a promising material for advancing technology across numerous domains. However, it is important to address the concerns regarding their toxicity, which remains a significant challenge in their application.\n"
          ]
        }
      ]
    }
  ]
}